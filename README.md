install dependency
download model from hugguing face
https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF

put the models under models/llama

Run the WebUI: chainlit run app.py -w